{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, TimeDistributed, Lambda\n",
    "from datetime import datetime, timedelta\n",
    "from numpy import array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class DeepAR(tf.keras.models.Model):\n",
    "    def __init__(self, lstm_units, n_steps_in, n_steps_out, n_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True, input_shape=(n_steps_in, n_features))\n",
    "        self.dense_mu = tf.keras.layers.Dense(1) \n",
    "        self.dense_sigma = tf.keras.layers.Dense(1, activation='softplus')\n",
    "\n",
    "    def call(self, inputs, initial_state=None):\n",
    "        outputs, state_h, state_c = self.lstm(inputs, initial_state=initial_state)\n",
    "\n",
    "        mu = self.dense_mu(outputs)\n",
    "        sigma = self.dense_sigma(outputs)\n",
    "        state = [state_h, state_c]\n",
    "\n",
    "        return [mu, sigma, state]\n",
    "\n",
    "def log_gaussian_loss(mu, sigma, y_true):\n",
    "    \"\"\"\n",
    "    Gaussian loss function\n",
    "    \"\"\"\n",
    "    return -tf.reduce_sum(tfp.distributions.Normal(loc=mu, scale=sigma).log_prob(y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义工具函数\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "n_steps_in = 30\n",
    "n_steps_out = 1\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:<class 'pandas.core.frame.DataFrame'>, shape:(15831, 1), min_index:2015-02-26 21:42:53, max_index:2015-04-22 20:52:53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-26 21:42:53</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-26 21:47:53</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-26 21:52:53</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-26 21:57:53</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-26 22:02:53</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "timestamp                 \n",
       "2015-02-26 21:42:53     57\n",
       "2015-02-26 21:47:53     43\n",
       "2015-02-26 21:52:53     55\n",
       "2015-02-26 21:57:53     64\n",
       "2015-02-26 22:02:53     93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_df = pd.read_csv(\"../../../2.1.datasets/Twitter_volume_AMZN.csv\", header=0, index_col=0)\n",
    "print(\"type:{}, shape:{}, min_index:{}, max_index:{}\".format(type(data_df), data_df.shape, data_df.index.min(), data_df.index.max()))\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (488661589.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    train_df = data_df[data_df.index <= test_cutoff_date]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 处理数据\n",
    "test_cutoff_date = datetime.strftime(datetime.strptime(data_df.index.max(), '%Y-%m-%d %H:%M:%S')- timedelta(days=50), '%Y-%m-%d %H:%M:%S'\n",
    "train_df = data_df[data_df.index <= test_cutoff_date]\n",
    "test_df = data_df[data_df.index > test_cutoff_date]\n",
    "\n",
    "training_mean = train_df.mean()\n",
    "training_std = train_df.std()\n",
    "training_value_df = (train_df - training_mean) / training_std \n",
    "\n",
    "test_mean = test_df.mean()\n",
    "test_std = test_df.std()\n",
    "test_value_df = (test_df - test_mean) / test_std\n",
    "\n",
    "X, y = split_sequence(training_value_df, n_steps_in, n_steps_out)\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
    "\n",
    "test_X, test_y = split_sequence(test_value_df, n_steps_in, n_steps_out)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_UNITS = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "model = DeepAR(LSTM_UNITS, n_steps_in, n_steps_out, n_features)\n",
    "\n",
    "# optmizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "# metric\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mu, sigma, _ = model(x)\n",
    "        loss = log_gaussian_loss(mu, sigma, y) # Forward Learning\n",
    "    # backword\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    rmse(y, mu)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_step(X, y)\n",
    "    print('Epoch %d, RMSE %.4f' % (epoch + 1, rmse.result().numpy()))\n",
    "    rmse.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링된 값들을 예측값으로 반환.\n",
    "pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape\n",
    "\n",
    "# median => 실제 예측값.\n",
    "# 5% 퍼센타일 => lower bound\n",
    "# 95% 퍼센타일 => upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape # 라벨의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lower_bound = []\n",
    "upper_bound = []\n",
    "median = []\n",
    "for step_pred in pred[0]:\n",
    "                           # 정규화된 값을 원래대로.\n",
    "  lb = (np.quantile(step_pred, 0.05) + test_mean) * test_std\n",
    "  ub = (np.quantile(step_pred, 0.95) + test_mean) * test_std\n",
    "  med = (np.quantile(step_pred, 0.5) + test_mean) * test_std\n",
    "  lower_bound.append(lb)\n",
    "  upper_bound.append(ub)\n",
    "  median.append(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "df['Close'].plot(ax=ax)\n",
    "ax.vlines('2020-08-22', 0, 1000, linestyle='--', color='r', label='forecast boundary')\n",
    "ax.fill_between(df_test[30:].index, lower_bound, upper_bound, color='b', alpha=0.1, label='95% Confidence Interval')\n",
    "ax.plot(df_test[30:].index, median, label='Prediction')\n",
    "ax.legend(loc='upper left')\n",
    "# plt.suptitle(f\"ARIMA {optimal[0][0]} Prediction Result (r2 score: {r2}\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6745e9648795706a7ca7e2de29bdd42842caad17d7fb689e8fa79981fec26a98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
